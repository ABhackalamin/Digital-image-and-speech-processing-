{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def compute_short_term_autocorrelation(cut_signal, sr, frame_length, hop_length, signal_type):\n",
    "    # Compute short-term autocorrelation\n",
    "    auto_corr = librosa.autocorrelate(y=cut_signal, max_size=frame_length)\n",
    "\n",
    "    # Plot speech waveform and autocorrelation\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot speech waveform\n",
    "    plt.subplot(2, 1, 1)\n",
    "    librosa.display.waveshow(cut_signal, sr=sr, alpha=0.5)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(signal_type + ' Speech Waveform (Cut for 30ms)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot autocorrelation\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(librosa.frames_to_time(range(len(auto_corr)), hop_length=hop_length), auto_corr)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.title('Short-term Autocorrelation of ' + signal_type + ' Speech Signal')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example\n",
    "audio_file = r\"/content/drive/MyDrive/harvard.wav\"\n",
    "\n",
    "# Load the audio file\n",
    "signal, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Parameters\n",
    "frame_duration = 0.03  # 30 ms frame duration\n",
    "hop_duration = frame_duration / 2  # Half of frame duration for 50% overlap\n",
    "\n",
    "# Convert durations to samples\n",
    "frame_length = int(sr * frame_duration)\n",
    "hop_length = int(sr * hop_duration)\n",
    "\n",
    "# Cut a portion of the speech signal (for example, for 30 ms)\n",
    "cut_signal = signal[int(5*sr):int(5.03*sr)]\n",
    "compute_short_term_autocorrelation(cut_signal, sr, frame_length, hop_length, 'Voiced')\n",
    "\n",
    "# Cut a portion of the speech signal (for example, for 30 ms)\n",
    "cut_signal = signal[int(4*sr):int(4.03*sr)]\n",
    "compute_short_term_autocorrelation(cut_signal, sr, frame_length, hop_length, 'Unvoiced')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
